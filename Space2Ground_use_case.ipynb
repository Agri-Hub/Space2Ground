{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ceb68a9",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f34c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c2fbf",
   "metadata": {},
   "source": [
    "## Load training and test Sentinel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3120a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"s1_colnames.txt\", \"r\") as f:\n",
    "    s1_colnames = f.read().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "66e93161",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_train = pd.read_csv('data/s1/train_dataset.csv', names = s1_colnames)\n",
    "s1_test = pd.read_csv('data/s1/test_dataset.csv', names = s1_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9ffc0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"s2_colnames.txt\", \"r\") as f:\n",
    "    s2_colnames = f.read().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5eb69918",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_train = pd.read_csv('data/s2/train_dataset.csv', names = s2_colnames)\n",
    "s2_test = pd.read_csv('data/s2/test_dataset.csv', names = s2_colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b04b1",
   "metadata": {},
   "source": [
    "## Calclulate class weights to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dce9d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(s2_train.label),\n",
    "                                        y = s2_train.label                                                 \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(s2_train.label), class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99bd3b",
   "metadata": {},
   "source": [
    "## Get monthly mean values of Sentinel-2 bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2e2479b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:05<00:00, 18.51s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "bands =  ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12']\n",
    "monthly_train = []\n",
    "s2_train_full = []\n",
    "for b in tqdm(bands):\n",
    "    df = s2_train.filter(regex=b)\n",
    "    s2_train_full.append(df)\n",
    "    df.columns = [pd.to_datetime(x.split(\"_\")[-1]).date().month  for x in df.columns]\n",
    "    df = df.groupby(level=0, axis=1).apply(lambda x: x.apply(np.mean, axis=1))\n",
    "    df = df.drop(columns = [3])\n",
    "    monthly_train.append(df)\n",
    "monthly_train = np.dstack(monthly_train)\n",
    "s2_train_full = np.dstack(s2_train_full)\n",
    "\n",
    "monthly_test = []\n",
    "s2_test_full = []\n",
    "for b in tqdm(bands):\n",
    "    df = s2_test.filter(regex=b)\n",
    "    s2_test_full.append(df)\n",
    "    df.columns = [pd.to_datetime(x.split(\"_\")[-1]).date().month  for x in df.columns]\n",
    "    df = df.groupby(level=0, axis=1).apply(lambda x: x.apply(np.mean, axis=1))\n",
    "    df = df.drop(columns = [3])\n",
    "    monthly_test.append(df)\n",
    "monthly_test = np.dstack(monthly_test)\n",
    "s2_test_full = np.dstack(s2_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "288515a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure correct order of S1 data\n",
    "s1_train = np.dstack([s1_train.filter(regex='VH_SAR'), s1_train.filter(regex='VV_SAR'), \n",
    "                      s1_train.filter(regex='VH_COH'), s1_train.filter(regex='VV_COH')])\n",
    "s1_test = np.dstack([s1_test.filter(regex='VH_SAR'), s1_test.filter(regex='VV_SAR'), \n",
    "                      s1_test.filter(regex='VH_COH'), s1_test.filter(regex='VV_COH')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb285f6",
   "metadata": {},
   "source": [
    "## Stack S1 and S2  together\n",
    "The final shape of the data is (n_samples, n_dates, n_bands).\n",
    "n_dates is equal to the total number of monthes, e.g. 7\n",
    "n_bands is equal to 14 with corresponds to 10 bands of Sentinel-2 and the 4 features of Sentinel-1 (VV/VH backscatter and coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "88eca95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30002, 7, 14) (3334, 7, 14)\n",
      "(30002, 2) (3334, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.dstack((monthly_train, s1_train))\n",
    "# X_train = s2_train_full.copy()\n",
    "X_test = np.dstack((monthly_test, s1_test))\n",
    "# X_test = s2_test_full.copy()\n",
    "y_train = pd.get_dummies(s2_train.label).values\n",
    "y_test = pd.get_dummies(s2_test.label).values\n",
    "ids_train = s2_train.iloc[:,1].values\n",
    "ids_test = s2_test.iloc[:,1].values\n",
    "X_train, X_val, y_train, y_val, ids_train, ids_val = train_test_split(\n",
    "            X_train, y_train, ids_train, test_size=0.1, random_state=420)\n",
    "print(X_train.shape, X_val.shape)\n",
    "print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9988ff6",
   "metadata": {},
   "source": [
    "## Train a custom lightweight model on the Satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "eb74dbf0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 12:36:39.284401: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2022-06-13 12:36:39.285281: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.4412 - categorical_accuracy: 0.8392\n",
      "Epoch 00001: val_loss improved from inf to 0.38656, saving model to model.h5\n",
      "118/118 [==============================] - 8s 67ms/step - loss: 0.4409 - categorical_accuracy: 0.8392 - val_loss: 0.3866 - val_categorical_accuracy: 0.8470\n",
      "Epoch 2/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3769 - categorical_accuracy: 0.8471\n",
      "Epoch 00002: val_loss did not improve from 0.38656\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.3773 - categorical_accuracy: 0.8468 - val_loss: 0.4027 - val_categorical_accuracy: 0.8656\n",
      "Epoch 3/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3528 - categorical_accuracy: 0.8601\n",
      "Epoch 00003: val_loss improved from 0.38656 to 0.31749, saving model to model.h5\n",
      "118/118 [==============================] - 8s 65ms/step - loss: 0.3527 - categorical_accuracy: 0.8600 - val_loss: 0.3175 - val_categorical_accuracy: 0.8791\n",
      "Epoch 4/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3241 - categorical_accuracy: 0.8769\n",
      "Epoch 00004: val_loss improved from 0.31749 to 0.30178, saving model to model.h5\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.3242 - categorical_accuracy: 0.8768 - val_loss: 0.3018 - val_categorical_accuracy: 0.8908\n",
      "Epoch 5/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3160 - categorical_accuracy: 0.8826\n",
      "Epoch 00005: val_loss improved from 0.30178 to 0.28662, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.3158 - categorical_accuracy: 0.8826 - val_loss: 0.2866 - val_categorical_accuracy: 0.8923\n",
      "Epoch 6/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3008 - categorical_accuracy: 0.8928\n",
      "Epoch 00006: val_loss improved from 0.28662 to 0.27633, saving model to model.h5\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.3010 - categorical_accuracy: 0.8926 - val_loss: 0.2763 - val_categorical_accuracy: 0.8950\n",
      "Epoch 7/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2828 - categorical_accuracy: 0.9034\n",
      "Epoch 00007: val_loss improved from 0.27633 to 0.25810, saving model to model.h5\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.2826 - categorical_accuracy: 0.9035 - val_loss: 0.2581 - val_categorical_accuracy: 0.9061\n",
      "Epoch 8/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2672 - categorical_accuracy: 0.9123\n",
      "Epoch 00008: val_loss did not improve from 0.25810\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.2670 - categorical_accuracy: 0.9123 - val_loss: 0.2683 - val_categorical_accuracy: 0.9061\n",
      "Epoch 9/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2519 - categorical_accuracy: 0.9188\n",
      "Epoch 00009: val_loss did not improve from 0.25810\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.2518 - categorical_accuracy: 0.9188 - val_loss: 0.2628 - val_categorical_accuracy: 0.9079\n",
      "Epoch 10/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2472 - categorical_accuracy: 0.9212\n",
      "Epoch 00010: val_loss did not improve from 0.25810\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2472 - categorical_accuracy: 0.9212 - val_loss: 0.2639 - val_categorical_accuracy: 0.9100\n",
      "Epoch 11/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2454 - categorical_accuracy: 0.9235\n",
      "Epoch 00011: val_loss improved from 0.25810 to 0.24087, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2453 - categorical_accuracy: 0.9235 - val_loss: 0.2409 - val_categorical_accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2392 - categorical_accuracy: 0.9259\n",
      "Epoch 00012: val_loss did not improve from 0.24087\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.2392 - categorical_accuracy: 0.9259 - val_loss: 0.2488 - val_categorical_accuracy: 0.9190\n",
      "Epoch 13/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2369 - categorical_accuracy: 0.9255\n",
      "Epoch 00013: val_loss did not improve from 0.24087\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2370 - categorical_accuracy: 0.9254 - val_loss: 0.2538 - val_categorical_accuracy: 0.9121\n",
      "Epoch 14/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2328 - categorical_accuracy: 0.9285\n",
      "Epoch 00014: val_loss improved from 0.24087 to 0.23134, saving model to model.h5\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.2329 - categorical_accuracy: 0.9285 - val_loss: 0.2313 - val_categorical_accuracy: 0.9271\n",
      "Epoch 15/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2264 - categorical_accuracy: 0.9321\n",
      "Epoch 00015: val_loss improved from 0.23134 to 0.22728, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2264 - categorical_accuracy: 0.9321 - val_loss: 0.2273 - val_categorical_accuracy: 0.9277\n",
      "Epoch 16/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2253 - categorical_accuracy: 0.9335\n",
      "Epoch 00016: val_loss did not improve from 0.22728\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.2251 - categorical_accuracy: 0.9336 - val_loss: 0.2344 - val_categorical_accuracy: 0.9262\n",
      "Epoch 17/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2207 - categorical_accuracy: 0.9342\n",
      "Epoch 00017: val_loss improved from 0.22728 to 0.22104, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2206 - categorical_accuracy: 0.9343 - val_loss: 0.2210 - val_categorical_accuracy: 0.9316\n",
      "Epoch 18/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2209 - categorical_accuracy: 0.9337\n",
      "Epoch 00018: val_loss did not improve from 0.22104\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2208 - categorical_accuracy: 0.9337 - val_loss: 0.2328 - val_categorical_accuracy: 0.9223\n",
      "Epoch 19/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2181 - categorical_accuracy: 0.9367\n",
      "Epoch 00019: val_loss did not improve from 0.22104\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.2183 - categorical_accuracy: 0.9366 - val_loss: 0.2298 - val_categorical_accuracy: 0.9304\n",
      "Epoch 20/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2157 - categorical_accuracy: 0.9369\n",
      "Epoch 00020: val_loss did not improve from 0.22104\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.2159 - categorical_accuracy: 0.9368 - val_loss: 0.2310 - val_categorical_accuracy: 0.9301\n",
      "Epoch 21/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2130 - categorical_accuracy: 0.9383\n",
      "Epoch 00021: val_loss did not improve from 0.22104\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2131 - categorical_accuracy: 0.9383 - val_loss: 0.2229 - val_categorical_accuracy: 0.9280\n",
      "Epoch 22/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2107 - categorical_accuracy: 0.9389\n",
      "Epoch 00022: val_loss did not improve from 0.22104\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.2107 - categorical_accuracy: 0.9389 - val_loss: 0.2212 - val_categorical_accuracy: 0.9301\n",
      "Epoch 23/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2103 - categorical_accuracy: 0.9379\n",
      "Epoch 00023: val_loss improved from 0.22104 to 0.21201, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2102 - categorical_accuracy: 0.9380 - val_loss: 0.2120 - val_categorical_accuracy: 0.9364\n",
      "Epoch 24/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2082 - categorical_accuracy: 0.9394\n",
      "Epoch 00024: val_loss improved from 0.21201 to 0.20898, saving model to model.h5\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.2080 - categorical_accuracy: 0.9395 - val_loss: 0.2090 - val_categorical_accuracy: 0.9352\n",
      "Epoch 25/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2065 - categorical_accuracy: 0.9404\n",
      "Epoch 00025: val_loss did not improve from 0.20898\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2063 - categorical_accuracy: 0.9404 - val_loss: 0.2148 - val_categorical_accuracy: 0.9349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2052 - categorical_accuracy: 0.9398\n",
      "Epoch 00026: val_loss did not improve from 0.20898\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2054 - categorical_accuracy: 0.9397 - val_loss: 0.2144 - val_categorical_accuracy: 0.9355\n",
      "Epoch 27/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2045 - categorical_accuracy: 0.9403\n",
      "Epoch 00027: val_loss improved from 0.20898 to 0.20436, saving model to model.h5\n",
      "118/118 [==============================] - 7s 60ms/step - loss: 0.2046 - categorical_accuracy: 0.9403 - val_loss: 0.2044 - val_categorical_accuracy: 0.9373\n",
      "Epoch 28/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1994 - categorical_accuracy: 0.9427\n",
      "Epoch 00028: val_loss did not improve from 0.20436\n",
      "118/118 [==============================] - 7s 59ms/step - loss: 0.1993 - categorical_accuracy: 0.9428 - val_loss: 0.2100 - val_categorical_accuracy: 0.9364\n",
      "Epoch 29/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2028 - categorical_accuracy: 0.9406\n",
      "Epoch 00029: val_loss improved from 0.20436 to 0.20382, saving model to model.h5\n",
      "118/118 [==============================] - 7s 58ms/step - loss: 0.2028 - categorical_accuracy: 0.9407 - val_loss: 0.2038 - val_categorical_accuracy: 0.9397\n",
      "Epoch 30/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1994 - categorical_accuracy: 0.9423\n",
      "Epoch 00030: val_loss did not improve from 0.20382\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.1991 - categorical_accuracy: 0.9424 - val_loss: 0.2087 - val_categorical_accuracy: 0.9355\n",
      "Epoch 31/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1962 - categorical_accuracy: 0.9444\n",
      "Epoch 00031: val_loss improved from 0.20382 to 0.20211, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1962 - categorical_accuracy: 0.9444 - val_loss: 0.2021 - val_categorical_accuracy: 0.9385\n",
      "Epoch 32/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1926 - categorical_accuracy: 0.9445\n",
      "Epoch 00032: val_loss did not improve from 0.20211\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.1927 - categorical_accuracy: 0.9444 - val_loss: 0.2043 - val_categorical_accuracy: 0.9397\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1920 - categorical_accuracy: 0.9451\n",
      "Epoch 00033: val_loss improved from 0.20211 to 0.19640, saving model to model.h5\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.1920 - categorical_accuracy: 0.9451 - val_loss: 0.1964 - val_categorical_accuracy: 0.9418\n",
      "Epoch 34/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1926 - categorical_accuracy: 0.9439\n",
      "Epoch 00034: val_loss improved from 0.19640 to 0.19535, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1926 - categorical_accuracy: 0.9439 - val_loss: 0.1954 - val_categorical_accuracy: 0.9403\n",
      "Epoch 35/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1918 - categorical_accuracy: 0.9450\n",
      "Epoch 00035: val_loss improved from 0.19535 to 0.19278, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1917 - categorical_accuracy: 0.9451 - val_loss: 0.1928 - val_categorical_accuracy: 0.9442\n",
      "Epoch 36/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1882 - categorical_accuracy: 0.9467\n",
      "Epoch 00036: val_loss did not improve from 0.19278\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1885 - categorical_accuracy: 0.9466 - val_loss: 0.1936 - val_categorical_accuracy: 0.9418\n",
      "Epoch 37/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1878 - categorical_accuracy: 0.9473\n",
      "Epoch 00037: val_loss did not improve from 0.19278\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.1878 - categorical_accuracy: 0.9474 - val_loss: 0.1942 - val_categorical_accuracy: 0.9451\n",
      "Epoch 38/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1856 - categorical_accuracy: 0.9475\n",
      "Epoch 00038: val_loss did not improve from 0.19278\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1856 - categorical_accuracy: 0.9475 - val_loss: 0.1982 - val_categorical_accuracy: 0.9454\n",
      "Epoch 39/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1860 - categorical_accuracy: 0.9481\n",
      "Epoch 00039: val_loss improved from 0.19278 to 0.18235, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1862 - categorical_accuracy: 0.9481 - val_loss: 0.1823 - val_categorical_accuracy: 0.9481\n",
      "Epoch 40/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1859 - categorical_accuracy: 0.9474\n",
      "Epoch 00040: val_loss did not improve from 0.18235\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1858 - categorical_accuracy: 0.9475 - val_loss: 0.1895 - val_categorical_accuracy: 0.9436\n",
      "Epoch 41/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1840 - categorical_accuracy: 0.9482\n",
      "Epoch 00041: val_loss did not improve from 0.18235\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.1838 - categorical_accuracy: 0.9482 - val_loss: 0.1873 - val_categorical_accuracy: 0.9463\n",
      "Epoch 42/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1837 - categorical_accuracy: 0.9487\n",
      "Epoch 00042: val_loss improved from 0.18235 to 0.18166, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1836 - categorical_accuracy: 0.9487 - val_loss: 0.1817 - val_categorical_accuracy: 0.9475\n",
      "Epoch 43/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1804 - categorical_accuracy: 0.9489\n",
      "Epoch 00043: val_loss did not improve from 0.18166\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1804 - categorical_accuracy: 0.9489 - val_loss: 0.1821 - val_categorical_accuracy: 0.9484\n",
      "Epoch 44/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1814 - categorical_accuracy: 0.9492\n",
      "Epoch 00044: val_loss did not improve from 0.18166\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1815 - categorical_accuracy: 0.9492 - val_loss: 0.1893 - val_categorical_accuracy: 0.9472\n",
      "Epoch 45/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1831 - categorical_accuracy: 0.9478\n",
      "Epoch 00045: val_loss did not improve from 0.18166\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1830 - categorical_accuracy: 0.9478 - val_loss: 0.1827 - val_categorical_accuracy: 0.9496\n",
      "Epoch 46/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1805 - categorical_accuracy: 0.9487\n",
      "Epoch 00046: val_loss did not improve from 0.18166\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1805 - categorical_accuracy: 0.9487 - val_loss: 0.1844 - val_categorical_accuracy: 0.9463\n",
      "Epoch 47/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1806 - categorical_accuracy: 0.9492\n",
      "Epoch 00047: val_loss did not improve from 0.18166\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.1803 - categorical_accuracy: 0.9492 - val_loss: 0.1904 - val_categorical_accuracy: 0.9442\n",
      "Epoch 48/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1773 - categorical_accuracy: 0.9507\n",
      "Epoch 00048: val_loss did not improve from 0.18166\n",
      "118/118 [==============================] - 7s 60ms/step - loss: 0.1776 - categorical_accuracy: 0.9506 - val_loss: 0.1856 - val_categorical_accuracy: 0.9466\n",
      "Epoch 49/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1756 - categorical_accuracy: 0.9498\n",
      "Epoch 00049: val_loss improved from 0.18166 to 0.18148, saving model to model.h5\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.1754 - categorical_accuracy: 0.9498 - val_loss: 0.1815 - val_categorical_accuracy: 0.9487\n",
      "Epoch 50/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1762 - categorical_accuracy: 0.9501\n",
      "Epoch 00050: val_loss improved from 0.18148 to 0.17853, saving model to model.h5\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1760 - categorical_accuracy: 0.9501 - val_loss: 0.1785 - val_categorical_accuracy: 0.9493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1741 - categorical_accuracy: 0.9508\n",
      "Epoch 00051: val_loss did not improve from 0.17853\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.1741 - categorical_accuracy: 0.9508 - val_loss: 0.1842 - val_categorical_accuracy: 0.9469\n",
      "Epoch 52/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1772 - categorical_accuracy: 0.9500\n",
      "Epoch 00052: val_loss did not improve from 0.17853\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.1771 - categorical_accuracy: 0.9500 - val_loss: 0.1876 - val_categorical_accuracy: 0.9484\n",
      "Epoch 53/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1776 - categorical_accuracy: 0.9497\n",
      "Epoch 00053: val_loss improved from 0.17853 to 0.17837, saving model to model.h5\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.1775 - categorical_accuracy: 0.9497 - val_loss: 0.1784 - val_categorical_accuracy: 0.9484\n",
      "Epoch 54/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1756 - categorical_accuracy: 0.9516\n",
      "Epoch 00054: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1755 - categorical_accuracy: 0.9516 - val_loss: 0.1855 - val_categorical_accuracy: 0.9508\n",
      "Epoch 55/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1747 - categorical_accuracy: 0.9502\n",
      "Epoch 00055: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.1746 - categorical_accuracy: 0.9503 - val_loss: 0.1894 - val_categorical_accuracy: 0.9460\n",
      "Epoch 56/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1731 - categorical_accuracy: 0.9512\n",
      "Epoch 00056: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1731 - categorical_accuracy: 0.9512 - val_loss: 0.1912 - val_categorical_accuracy: 0.9466\n",
      "Epoch 57/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1712 - categorical_accuracy: 0.9517\n",
      "Epoch 00057: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1713 - categorical_accuracy: 0.9517 - val_loss: 0.1871 - val_categorical_accuracy: 0.9505\n",
      "Epoch 58/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1724 - categorical_accuracy: 0.9514\n",
      "Epoch 00058: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1722 - categorical_accuracy: 0.9515 - val_loss: 0.1902 - val_categorical_accuracy: 0.9478\n",
      "Epoch 59/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1695 - categorical_accuracy: 0.9524\n",
      "Epoch 00059: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.1694 - categorical_accuracy: 0.9524 - val_loss: 0.1886 - val_categorical_accuracy: 0.9478\n",
      "Epoch 60/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1690 - categorical_accuracy: 0.9527\n",
      "Epoch 00060: val_loss did not improve from 0.17837\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "118/118 [==============================] - 7s 58ms/step - loss: 0.1690 - categorical_accuracy: 0.9527 - val_loss: 0.1904 - val_categorical_accuracy: 0.9457\n",
      "Epoch 61/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1624 - categorical_accuracy: 0.9542\n",
      "Epoch 00061: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.1625 - categorical_accuracy: 0.9541 - val_loss: 0.1796 - val_categorical_accuracy: 0.9505\n",
      "Epoch 62/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1587 - categorical_accuracy: 0.9560\n",
      "Epoch 00062: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1587 - categorical_accuracy: 0.9560 - val_loss: 0.1809 - val_categorical_accuracy: 0.9508\n",
      "Epoch 63/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1579 - categorical_accuracy: 0.9558\n",
      "Epoch 00063: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1580 - categorical_accuracy: 0.9558 - val_loss: 0.1824 - val_categorical_accuracy: 0.9496\n",
      "Epoch 64/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1568 - categorical_accuracy: 0.9563\n",
      "Epoch 00064: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1568 - categorical_accuracy: 0.9563 - val_loss: 0.1830 - val_categorical_accuracy: 0.9520\n",
      "Epoch 65/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1568 - categorical_accuracy: 0.9563\n",
      "Epoch 00065: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1568 - categorical_accuracy: 0.9563 - val_loss: 0.1850 - val_categorical_accuracy: 0.9496\n",
      "Epoch 66/100\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1566 - categorical_accuracy: 0.9569\n",
      "Epoch 00066: val_loss did not improve from 0.17837\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1568 - categorical_accuracy: 0.9568 - val_loss: 0.1862 - val_categorical_accuracy: 0.9502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9371    0.7177    0.8129       581\n",
      "           1     0.9497    0.9910    0.9699      3124\n",
      "\n",
      "    accuracy                         0.9482      3705\n",
      "   macro avg     0.9434    0.8544    0.8914      3705\n",
      "weighted avg     0.9477    0.9482    0.9453      3705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 0.001\n",
    "sat_model_filename = \"lstm_att\"\n",
    "if os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "model_path = \"models/{}.h5\".format(sat_model_filename)\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', \n",
    "                             verbose=1, save_best_only=True, save_weights_only=False, mode='auto')  \n",
    "\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0.001, patience=10, verbose=0, mode='auto')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=0.0001)\n",
    "\n",
    "dropout = 0.5\n",
    "layers = [256, 128]\n",
    "batch_size = 256\n",
    "n_steps = X_train.shape[1]\n",
    "mdl = model_train(X_train, y_train, X_val, y_val, file_path, n_features = 14, n_steps = n_steps,\n",
    "                  scale = scale, batch_size = batch_size, n_classes = 2,class_weights = None,\n",
    "                  layers = layers, dropout = dropout, lr = lr)\n",
    "y_pred = np.argmax(mdl.predict(X_test), axis = 1)\n",
    "print(classification_report(np.argmax(y_test, axis = 1), y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a8981",
   "metadata": {},
   "source": [
    "## Create generators to train a CNN on the street-level images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "19f08185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2904 images belonging to 2 classes.\n",
      "Found 364 images belonging to 2 classes.\n",
      "Found 363 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "IMG_SIZE = 150\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 2\n",
    "train_dir = \"data/streetLevel_patches/train/\"\n",
    "test_dir = \"data/streetLevel_patches/test/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(IMG_SIZE,IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        color_mode='rgb',\n",
    "        shuffle=True,\n",
    "        class_mode='binary',\n",
    "        subset=\"training\",\n",
    "        classes=['Grassland', 'Non_Grassland'])\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.5\n",
    ")\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    subset=\"training\",\n",
    "    classes=['Grassland', 'Non_Grassland']\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    subset=\"validation\",\n",
    "    classes=['Grassland', 'Non_Grassland']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6450255",
   "metadata": {},
   "source": [
    "## Calclulate class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6cc4bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_grass = len(os.listdir(train_dir + 'Grassland'))\n",
    "total_train_nongrass = len(os.listdir(train_dir + 'Non_Grassland'))\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes = [0,1], \n",
    "                                                  y=[0]*total_train_grass + [1]*total_train_nongrass)\n",
    "class_weights = {i : class_weights[i] for i in range(2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b28ac",
   "metadata": {},
   "source": [
    "## Fine-tune a pre-trained InceptionV3 network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "03deb451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.9008 - acc: 0.6021 - f1_m: 0.2826 - recall_m: 0.6333 - precision_m: 0.2345\n",
      "Epoch 00001: val_loss improved from inf to 0.28979, saving model to /nfs/data2/IVMSP_callisto/Images/binary/models/inceptionv3.h5\n",
      "45/45 [==============================] - 39s 861ms/step - loss: 1.9008 - acc: 0.6021 - f1_m: 0.2826 - recall_m: 0.6333 - precision_m: 0.2345 - val_loss: 0.2898 - val_acc: 0.8969 - val_f1_m: 0.5835 - val_recall_m: 0.6655 - val_precision_m: 0.5380\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7293 - acc: 0.7275 - f1_m: 0.4034 - recall_m: 0.7290 - precision_m: 0.3231\n",
      "Epoch 00002: val_loss improved from 0.28979 to 0.28946, saving model to /nfs/data2/IVMSP_callisto/Images/binary/models/inceptionv3.h5\n",
      "45/45 [==============================] - 29s 640ms/step - loss: 0.7293 - acc: 0.7275 - f1_m: 0.4034 - recall_m: 0.7290 - precision_m: 0.3231 - val_loss: 0.2895 - val_acc: 0.9031 - val_f1_m: 0.6017 - val_recall_m: 0.7222 - val_precision_m: 0.5305\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5664 - acc: 0.7651 - f1_m: 0.4194 - recall_m: 0.7522 - precision_m: 0.3149\n",
      "Epoch 00003: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.5664 - acc: 0.7651 - f1_m: 0.4194 - recall_m: 0.7522 - precision_m: 0.3149 - val_loss: 0.3340 - val_acc: 0.9187 - val_f1_m: 0.6245 - val_recall_m: 0.6181 - val_precision_m: 0.6405\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4743 - acc: 0.7880 - f1_m: 0.4415 - recall_m: 0.7634 - precision_m: 0.3277\n",
      "Epoch 00004: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 28s 615ms/step - loss: 0.4743 - acc: 0.7880 - f1_m: 0.4415 - recall_m: 0.7634 - precision_m: 0.3277 - val_loss: 0.3118 - val_acc: 0.9281 - val_f1_m: 0.6866 - val_recall_m: 0.7267 - val_precision_m: 0.6567\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4092 - acc: 0.8338 - f1_m: 0.5071 - recall_m: 0.7725 - precision_m: 0.4005\n",
      "Epoch 00005: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.4092 - acc: 0.8338 - f1_m: 0.5071 - recall_m: 0.7725 - precision_m: 0.4005 - val_loss: 0.3055 - val_acc: 0.8969 - val_f1_m: 0.6161 - val_recall_m: 0.7524 - val_precision_m: 0.5285\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3995 - acc: 0.8401 - f1_m: 0.5094 - recall_m: 0.7517 - precision_m: 0.4160\n",
      "Epoch 00006: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.3995 - acc: 0.8401 - f1_m: 0.5094 - recall_m: 0.7517 - precision_m: 0.4160 - val_loss: 0.3039 - val_acc: 0.9219 - val_f1_m: 0.6605 - val_recall_m: 0.7322 - val_precision_m: 0.6081\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3888 - acc: 0.8549 - f1_m: 0.5268 - recall_m: 0.7418 - precision_m: 0.4318\n",
      "Epoch 00007: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 28s 611ms/step - loss: 0.3888 - acc: 0.8549 - f1_m: 0.5268 - recall_m: 0.7418 - precision_m: 0.4318 - val_loss: 0.3956 - val_acc: 0.8844 - val_f1_m: 0.6029 - val_recall_m: 0.7427 - val_precision_m: 0.5195\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4003 - acc: 0.8722 - f1_m: 0.5717 - recall_m: 0.7727 - precision_m: 0.4666\n",
      "Epoch 00008: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 0.4003 - acc: 0.8722 - f1_m: 0.5717 - recall_m: 0.7727 - precision_m: 0.4666 - val_loss: 0.3385 - val_acc: 0.9156 - val_f1_m: 0.6620 - val_recall_m: 0.8264 - val_precision_m: 0.5541\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3672 - acc: 0.8891 - f1_m: 0.5935 - recall_m: 0.7469 - precision_m: 0.5120\n",
      "Epoch 00009: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.3672 - acc: 0.8891 - f1_m: 0.5935 - recall_m: 0.7469 - precision_m: 0.5120 - val_loss: 0.3137 - val_acc: 0.9219 - val_f1_m: 0.6853 - val_recall_m: 0.8022 - val_precision_m: 0.6514\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3455 - acc: 0.8954 - f1_m: 0.6156 - recall_m: 0.7680 - precision_m: 0.5294\n",
      "Epoch 00010: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.3455 - acc: 0.8954 - f1_m: 0.6156 - recall_m: 0.7680 - precision_m: 0.5294 - val_loss: 0.2902 - val_acc: 0.9187 - val_f1_m: 0.7056 - val_recall_m: 0.7862 - val_precision_m: 0.6533\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3389 - acc: 0.9011 - f1_m: 0.6277 - recall_m: 0.7638 - precision_m: 0.5529\n",
      "Epoch 00011: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.3389 - acc: 0.9011 - f1_m: 0.6277 - recall_m: 0.7638 - precision_m: 0.5529 - val_loss: 0.3277 - val_acc: 0.9125 - val_f1_m: 0.6802 - val_recall_m: 0.8967 - val_precision_m: 0.5570\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3414 - acc: 0.9035 - f1_m: 0.6565 - recall_m: 0.8232 - precision_m: 0.5807\n",
      "Epoch 00012: val_loss did not improve from 0.28946\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 0.3414 - acc: 0.9035 - f1_m: 0.6565 - recall_m: 0.8232 - precision_m: 0.5807 - val_loss: 0.3555 - val_acc: 0.9187 - val_f1_m: 0.7198 - val_recall_m: 0.8489 - val_precision_m: 0.6337\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3239 - acc: 0.9053 - f1_m: 0.6359 - recall_m: 0.7983 - precision_m: 0.5529\n",
      "Epoch 00013: val_loss improved from 0.28946 to 0.27140, saving model to /nfs/data2/IVMSP_callisto/Images/binary/models/inceptionv3.h5\n",
      "45/45 [==============================] - 29s 636ms/step - loss: 0.3239 - acc: 0.9053 - f1_m: 0.6359 - recall_m: 0.7983 - precision_m: 0.5529 - val_loss: 0.2714 - val_acc: 0.8906 - val_f1_m: 0.6190 - val_recall_m: 0.7961 - val_precision_m: 0.5103\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3018 - acc: 0.8965 - f1_m: 0.6319 - recall_m: 0.8380 - precision_m: 0.5313\n",
      "Epoch 00014: val_loss did not improve from 0.27140\n",
      "45/45 [==============================] - 28s 624ms/step - loss: 0.3018 - acc: 0.8965 - f1_m: 0.6319 - recall_m: 0.8380 - precision_m: 0.5313 - val_loss: 0.2763 - val_acc: 0.8969 - val_f1_m: 0.6365 - val_recall_m: 0.8406 - val_precision_m: 0.5333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_filename = \"inceptionv3\"\n",
    "\n",
    "model_path = \"models/{}.h5\".format(model_filename)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', \n",
    "                             verbose=1, save_best_only=True, save_weights_only=False, mode='auto')  \n",
    "\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0.001, patience=10, verbose=0, mode='auto')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=0.0001)\n",
    "\n",
    "EPOCHS = 100\n",
    "base_model = InceptionV3(input_shape = (150, 150, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = tf.keras.layers.Flatten()(base_model.output)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9), \n",
    "              loss = 'binary_crossentropy',metrics = ['acc', f1_m, recall_m, precision_m])\n",
    "inceptv3_hist = model.fit(train_generator,\n",
    "    epochs = EPOCHS, \n",
    "    steps_per_epoch = train_generator.samples//BATCH_SIZE, \n",
    "    validation_data = val_generator, \n",
    "    validation_steps = val_generator.samples//BATCH_SIZE,  \n",
    "    verbose = 1, \n",
    "    callbacks = [checkpoint, early, reduce_lr], \n",
    "    class_weight = class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "aef37239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7848 images belonging to 2 classes.\n",
      "Found 2254 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# New data generators for prediction of all images\n",
    "\n",
    "train_datagen_p = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "train_datagen_p = train_datagen_p.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(IMG_SIZE,IMG_SIZE),\n",
    "        batch_size=1,\n",
    "        color_mode='rgb',\n",
    "        shuffle=False,\n",
    "        class_mode='binary',\n",
    "        subset=\"training\",\n",
    "        classes=['Grassland', 'Maize'])\n",
    "\n",
    "test_datagen_p = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "test_datagen_p = test_datagen_p.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=1,\n",
    "    color_mode='rgb',\n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    subset=\"training\",\n",
    "    classes=['Grassland', 'Maize']\n",
    ")\n",
    "\n",
    "filenames_train = train_datagen_p.filenames\n",
    "nb_samples_train = len(filenames_train)\n",
    "filenames_test = test_datagen_p.filenames\n",
    "nb_samples_test = len(filenames_test)\n",
    "\n",
    "predict_train = model.predict_generator(train_datagen_p,steps = nb_samples_train)\n",
    "predict_test = model.predict_generator(test_datagen_p,steps = nb_samples_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af87c1",
   "metadata": {},
   "source": [
    "## Combine predictions of satellite data and street-level images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "718f918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapillary = pd.read_csv('parcel_annotations.csv ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "05e1b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we get the result from the ground level for all instances\n",
    "probs = list(predict_train.flatten()) + list(predict_test.flatten())\n",
    "names = [int(x.split(\"/\")[1].split(\"_\")[0]) for x in filenames_train + filenames_test]\n",
    "direction = [x.split(\"/\")[1].split(\"_\")[1].split('.')[0] for x in filenames_train + filenames_test]\n",
    "results = pd.DataFrame([names, direction, probs]).T\n",
    "results.columns = ['image_id', 'direction', 'inception_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "478837db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then the results are merged with the rest of the information we have for each image\n",
    "# in order to link it with the corresponing parcel\n",
    "results = pd.merge(mapillary, results, on = ['image_id', 'direction'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7a770971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now exctract the prediction for all instaces from the space level\n",
    "X_all = np.vstack([X_train, X_val, X_test])\n",
    "ids_all = list(ids_train) + list(ids_val) + list(ids_test)\n",
    "predictions_all = mdl.predict(X_all)\n",
    "sat_preds = pd.DataFrame([ids_all, predictions_all[:,0]]).T\n",
    "sat_preds.columns = ['id', 'sat_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f35a9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally we merge in a single DataFrame the two different predictions\n",
    "space2ground = pd.merge(results, sat_preds, on = ['id'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0a2d90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "space2ground['ground_pred'] = 'Grassland'\n",
    "space2ground['space_pred'] = 'Grassland'\n",
    "space2ground.loc[space2ground.inception_prob > 0.5, 'ground_pred'] = 'Non_Grassland'\n",
    "space2ground.loc[space2ground.sat_prob > 0.5, 'space_pred'] = 'Non_Grassland'\n",
    "space2ground.loc[space2ground.label != 'Grassland'] = 'Non_Grassland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "12427843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_date</th>\n",
       "      <th>image_id</th>\n",
       "      <th>direction</th>\n",
       "      <th>inception_prob</th>\n",
       "      <th>sat_prob</th>\n",
       "      <th>ground_pred</th>\n",
       "      <th>space_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>18649</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>5458128290896369</td>\n",
       "      <td>right</td>\n",
       "      <td>0.133706</td>\n",
       "      <td>0.624789</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>18649</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>3696418997152258</td>\n",
       "      <td>right</td>\n",
       "      <td>0.302674</td>\n",
       "      <td>0.624789</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>17328</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>2826001634381413</td>\n",
       "      <td>left</td>\n",
       "      <td>0.579689</td>\n",
       "      <td>0.822648</td>\n",
       "      <td>Non_Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>17328</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>500336977985307</td>\n",
       "      <td>left</td>\n",
       "      <td>0.573389</td>\n",
       "      <td>0.822648</td>\n",
       "      <td>Non_Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>8605</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>4275714419175593</td>\n",
       "      <td>left</td>\n",
       "      <td>0.439639</td>\n",
       "      <td>0.587774</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>8605</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>212647310321771</td>\n",
       "      <td>right</td>\n",
       "      <td>0.524626</td>\n",
       "      <td>0.587774</td>\n",
       "      <td>Non_Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>8605</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>283619173500861</td>\n",
       "      <td>right</td>\n",
       "      <td>0.518648</td>\n",
       "      <td>0.587774</td>\n",
       "      <td>Non_Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>8605</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>500827311102460</td>\n",
       "      <td>right</td>\n",
       "      <td>0.854017</td>\n",
       "      <td>0.587774</td>\n",
       "      <td>Non_Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>3938</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>215088676792486</td>\n",
       "      <td>left</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>Non_Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>3938</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>2001635236653224</td>\n",
       "      <td>right</td>\n",
       "      <td>0.99993</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>Non_Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7188</th>\n",
       "      <td>863</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>2777374049242497</td>\n",
       "      <td>right</td>\n",
       "      <td>0.89016</td>\n",
       "      <td>0.676516</td>\n",
       "      <td>Non_Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>863</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>507297060295539</td>\n",
       "      <td>right</td>\n",
       "      <td>0.802916</td>\n",
       "      <td>0.676516</td>\n",
       "      <td>Non_Grassland</td>\n",
       "      <td>Non_Grassland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      label  image_date          image_id direction inception_prob  \\\n",
       "803   18649  Grassland  2017-05-07  5458128290896369     right       0.133706   \n",
       "804   18649  Grassland  2017-05-07  3696418997152258     right       0.302674   \n",
       "3198  17328  Grassland  2017-07-30  2826001634381413      left       0.579689   \n",
       "3199  17328  Grassland  2017-07-30   500336977985307      left       0.573389   \n",
       "3250   8605  Grassland  2017-05-17  4275714419175593      left       0.439639   \n",
       "3251   8605  Grassland  2017-04-02   212647310321771     right       0.524626   \n",
       "3252   8605  Grassland  2017-04-02   283619173500861     right       0.518648   \n",
       "3253   8605  Grassland  2017-04-02   500827311102460     right       0.854017   \n",
       "4719   3938  Grassland  2017-10-10   215088676792486      left       0.999936   \n",
       "4720   3938  Grassland  2017-10-10  2001635236653224     right        0.99993   \n",
       "7188    863  Grassland  2017-10-10  2777374049242497     right        0.89016   \n",
       "7189    863  Grassland  2017-10-10   507297060295539     right       0.802916   \n",
       "\n",
       "      sat_prob    ground_pred     space_pred  \n",
       "803   0.624789      Grassland  Non_Grassland  \n",
       "804   0.624789      Grassland  Non_Grassland  \n",
       "3198  0.822648  Non_Grassland  Non_Grassland  \n",
       "3199  0.822648  Non_Grassland  Non_Grassland  \n",
       "3250  0.587774      Grassland  Non_Grassland  \n",
       "3251  0.587774  Non_Grassland  Non_Grassland  \n",
       "3252  0.587774  Non_Grassland  Non_Grassland  \n",
       "3253  0.587774  Non_Grassland  Non_Grassland  \n",
       "4719  0.991723  Non_Grassland  Non_Grassland  \n",
       "4720  0.991723  Non_Grassland  Non_Grassland  \n",
       "7188  0.676516  Non_Grassland  Non_Grassland  \n",
       "7189  0.676516  Non_Grassland  Non_Grassland  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space2ground[space2ground.space_pred != space2ground.label]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
